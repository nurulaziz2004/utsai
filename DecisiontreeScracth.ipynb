{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXJ8LI5RR33G",
        "outputId": "3e605204-2b5e-44d4-edfa-2b3594f3f6e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data sample:\n",
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "=== CEK NILAI KOSONG (NaN) SEBELUM DIBERSIHKAN ===\n",
            "Pregnancies                 0\n",
            "Glucose                     0\n",
            "BloodPressure               0\n",
            "SkinThickness               0\n",
            "Insulin                     0\n",
            "BMI                         0\n",
            "DiabetesPedigreeFunction    0\n",
            "Age                         0\n",
            "Outcome                     0\n",
            "dtype: int64\n",
            "\n",
            "=== JUMLAH NOL (yang dianggap missing) per kolom ===\n",
            "Glucose            5\n",
            "BloodPressure     35\n",
            "SkinThickness    227\n",
            "Insulin          374\n",
            "BMI               11\n",
            "dtype: int64\n",
            "\n",
            "=== CEK NILAI KOSONG (NaN) SETELAH DIBERSIHKAN ===\n",
            "Pregnancies                 0\n",
            "Glucose                     0\n",
            "BloodPressure               0\n",
            "SkinThickness               0\n",
            "Insulin                     0\n",
            "BMI                         0\n",
            "DiabetesPedigreeFunction    0\n",
            "Age                         0\n",
            "Outcome                     0\n",
            "dtype: int64\n",
            "\n",
            "Jumlah data setelah pembersihan: 392\n",
            " Menghapus fitur 'BloodPressure' (indeks 2), sisa 7 fitur.\n",
            " Menghapus fitur 'Pregnancies' (indeks 0), sisa 6 fitur.\n",
            " Menghapus fitur 'Insulin' (indeks 4), sisa 5 fitur.\n",
            "\n",
            "Fitur terpilih (berdasarkan nama): ['Glucose', 'SkinThickness', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
            "\n",
            "=== HASIL EVALUASI ===\n",
            "Akurasi: 0.7457627118644068\n",
            "Confusion Matrix:\n",
            "[[60 20]\n",
            " [10 28]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.75      0.80        80\n",
            "           1       0.58      0.74      0.65        38\n",
            "\n",
            "    accuracy                           0.75       118\n",
            "   macro avg       0.72      0.74      0.73       118\n",
            "weighted avg       0.77      0.75      0.75       118\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ==============================================\n",
        "# Fungsi Gini Impurity\n",
        "# ==============================================\n",
        "def gini_impurity(y):                                # hitung impurity Gini untuk vektor label y\n",
        "    \"\"\"Hitung impurity Gini dari label y\"\"\"\n",
        "    hist = np.bincount(y)                            # jumlah kemunculan tiap kelas\n",
        "    ps = hist / len(y)                               # proporsi tiap kelas\n",
        "    return 1 - np.sum(ps ** 2)                       # rumus Gini = 1 - sum(p_k^2)\n",
        "\n",
        "# ==============================================\n",
        "# Struktur Node dan Decision Tree\n",
        "# ==============================================\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
        "        self.feature = feature                        # index fitur yang dipakai split\n",
        "        self.threshold = threshold                    # nilai ambang split\n",
        "        self.left = left                              # anak kiri\n",
        "        self.right = right                            # anak kanan\n",
        "        self.value = value                            # nilai kelas bila leaf\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None                 # leaf jika punya nilai kelas\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=5, n_feats=None):\n",
        "        self.min_samples_split = min_samples_split    # minimal sampel utk boleh displit\n",
        "        self.max_depth = max_depth                    # kedalaman maksimum pohon\n",
        "        self.n_feats = n_feats                        # jumlah fitur acak per node (None=pakai semua)\n",
        "        self.root = None                              # root node\n",
        "        self.feature_importances_ = None              # simpan \"pentingnya\" fitur (versi sederhana)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])  # set n_feats\n",
        "        self.root = self._grow_tree(X, y)             # bangun pohon mulai dari root\n",
        "        self.feature_importances_ = self._compute_feature_importance(X)  # hitung importance (frekuensi split)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])  # telusuri pohon utk tiap sampel\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))                  # jumlah kelas unik pada node ini\n",
        "\n",
        "        # Kriteria berhenti membelah node\n",
        "        if (depth >= self.max_depth) or (n_labels == 1) or (n_samples < self.min_samples_split):\n",
        "            leaf_value = self._most_common_label(y)   # jadikan leaf dengan kelas mayoritas\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)  # pilih subset fitur (acak)\n",
        "\n",
        "        # Cari split terbaik pada fitur-fitur terpilih\n",
        "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
        "        if best_feat is None:                         # jika tak ada gain, jadikan leaf\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)  # indeks kiri/kanan\n",
        "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)   # rekursi ke kiri\n",
        "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)# rekursi ke kanan\n",
        "        return Node(best_feat, best_thresh, left, right)                    # kembalikan node internal\n",
        "\n",
        "    def _best_criteria(self, X, y, feat_idxs):\n",
        "        best_gain = -1                                 # simpan information gain terbaik\n",
        "        split_idx, split_thresh = None, None\n",
        "        for feat_idx in feat_idxs:                     # cek tiap fitur kandidat\n",
        "            X_column = X[:, feat_idx]\n",
        "            thresholds = np.unique(X_column)           # coba semua nilai unik sebagai threshold\n",
        "            for threshold in thresholds:\n",
        "                gain = self._information_gain(y, X_column, threshold)  # hitung gain\n",
        "                if gain > best_gain:                   # simpan jika lebih baik\n",
        "                    best_gain = gain\n",
        "                    split_idx = feat_idx\n",
        "                    split_thresh = threshold\n",
        "        return split_idx, split_thresh                 # kembalikan fitur & ambang terbaik\n",
        "\n",
        "    def _information_gain(self, y, X_column, split_thresh):\n",
        "        parent_loss = gini_impurity(y)                 # impurity node induk\n",
        "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
        "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
        "            return 0                                   # jika salah satu sisi kosong → tak ada gain\n",
        "\n",
        "        n = len(y)\n",
        "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
        "        g_l, g_r = gini_impurity(y[left_idxs]), gini_impurity(y[right_idxs])  # impurity anak\n",
        "        child_loss = (n_l / n) * g_l + (n_r / n) * g_r                         # impurity tertimbang\n",
        "        return parent_loss - child_loss                # IG = impurity parent − impurity anak\n",
        "\n",
        "    def _split(self, X_column, split_thresh):\n",
        "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()   # ke kiri jika ≤ threshold\n",
        "        right_idxs = np.argwhere(X_column > split_thresh).flatten()   # ke kanan jika > threshold\n",
        "        return left_idxs, right_idxs\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        if node.is_leaf_node():\n",
        "            return node.value                         # kembalikan kelas leaf\n",
        "        if x[node.feature] <= node.threshold:         # bandingkan fitur sampel dengan ambang\n",
        "            return self._traverse_tree(x, node.left)  # telusuri kiri\n",
        "        return self._traverse_tree(x, node.right)     # atau kanan\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        counter = Counter(y)                          # hitung frekuensi label\n",
        "        most_common = counter.most_common(1)[0][0]    # ambil label terbanyak\n",
        "        return most_common\n",
        "\n",
        "    def _compute_feature_importance(self, X):\n",
        "        \"\"\"Hitung importance fitur berdasarkan frekuensi fitur digunakan\"\"\"\n",
        "        importance = np.zeros(X.shape[1])             # inisialisasi vektor importance\n",
        "        self._traverse_and_count(self.root, importance)  # tambah 1 tiap kali fitur jadi split\n",
        "        if importance.sum() > 0:\n",
        "            importance = importance / importance.sum()   # normalisasi ke proporsi\n",
        "        return importance\n",
        "\n",
        "    def _traverse_and_count(self, node, importance):\n",
        "        if node is None or node.is_leaf_node():\n",
        "            return                                   # berhenti di leaf\n",
        "        importance[node.feature] += 1                # fitur ini dipakai split → tambah count\n",
        "        self._traverse_and_count(node.left, importance)\n",
        "        self._traverse_and_count(node.right, importance)\n",
        "\n",
        "# ==============================================\n",
        "# FUNGSI RFE (Recursive Feature Elimination)\n",
        "# ==============================================\n",
        "def recursive_feature_elimination(X, y, n_features_to_keep, feature_names):\n",
        "    \"\"\"Hapus fitur paling tidak penting sampai tersisa n_features_to_keep\"\"\"\n",
        "    features = np.arange(X.shape[1])                  # indeks awal semua fitur\n",
        "    feature_names = np.array(feature_names)\n",
        "\n",
        "    while len(features) > n_features_to_keep:         # iterasi sampai sisa n_features_to_keep\n",
        "        clf = DecisionTree(max_depth=5)               # latih pohon pada subset fitur saat ini\n",
        "        clf.fit(X[:, features], y)\n",
        "        importances = clf.feature_importances_        # importance versi 'frekuensi split'\n",
        "\n",
        "        if importances.sum() == 0:                    # jika semua nol → hentikan\n",
        "            print(\"⚠ Semua fitur sama pentingnya, proses dihentikan.\")\n",
        "            break\n",
        "\n",
        "        least_important = np.argmin(importances)      # cari fitur paling tidak penting\n",
        "        print(f\" Menghapus fitur '{feature_names[features[least_important]]}' (indeks {features[least_important]}), sisa {len(features)-1} fitur.\")\n",
        "        features = np.delete(features, least_important)  # buang fitur tsb\n",
        "\n",
        "    return features, feature_names[features]          # kembalikan indeks & nama fitur tersisa\n",
        "\n",
        "# ==============================================\n",
        "# MAIN PROGRAM\n",
        "# ==============================================\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(\"https://raw.githubusercontent.com/nurulaziz2004/utsai/main/datadt.csv\")  # ambil data\n",
        "    print(\"Data sample:\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Analisis & pembersihan data awal\n",
        "    print(\"=== CEK NILAI KOSONG (NaN) SEBELUM DIBERSIHKAN ===\")\n",
        "    print(df.isna().sum())                            # cek NaN murni\n",
        "\n",
        "    # Pastikan semua kolom numerik (antisipasi kolom object)\n",
        "    for c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors='coerce') # coercion → non-numerik jadi NaN\n",
        "\n",
        "    # Kolom fisiologis yang tak logis bernilai 0 → anggap missing\n",
        "    cols_zero_means_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "    print(\"\\n=== JUMLAH NOL (yang dianggap missing) per kolom ===\")\n",
        "    print(df[cols_zero_means_missing].eq(0).sum())    # hitung banyaknya 0 per kolom\n",
        "\n",
        "    # Ubah 0 → NaN agar dianggap missing\n",
        "    df[cols_zero_means_missing] = df[cols_zero_means_missing].replace(0, np.nan)\n",
        "\n",
        "    # (Opsional) juga bersihkan inf/-inf\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Strategi pembersihan:\n",
        "    # A) Drop baris yang mengandung NaN pada kolom penting (mengurangi jumlah data)\n",
        "    df = df.dropna(subset=cols_zero_means_missing)\n",
        "\n",
        "    # B) Alternatif (komentari A, aktifkan ini) → imputasi median agar baris tetap banyak\n",
        "    # for c in cols_zero_means_missing:\n",
        "    #     df[c] = df[c].fillna(df[c].median())\n",
        "\n",
        "    df = df.drop_duplicates()                         # hapus baris duplikat (jika ada)\n",
        "\n",
        "    print(\"\\n=== CEK NILAI KOSONG (NaN) SETELAH DIBERSIHKAN ===\")\n",
        "    print(df.isna().sum())\n",
        "    print(\"\\nJumlah data setelah pembersihan:\", len(df))\n",
        "\n",
        "    # Pisahkan fitur dan target (asumsi kolom terakhir = target)\n",
        "    X = df.iloc[:, :-1].values                        # semua kolom kecuali terakhir → fitur\n",
        "    y = df.iloc[:, -1].values.astype(int)             # kolom terakhir → label (int)\n",
        "    feature_names = df.columns[:-1]                   # nama kolom fitur\n",
        "\n",
        "    # Jalankan RFE untuk memilih 5 fitur terbaik\n",
        "    selected_features, selected_names = recursive_feature_elimination(\n",
        "        X, y, n_features_to_keep=5, feature_names=feature_names\n",
        "    )\n",
        "    print(\"\\nFitur terpilih (berdasarkan nama):\", list(selected_names))\n",
        "\n",
        "    # Split data (pakai random_state agar replikasi konsisten; bisa tambah stratify=y)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X[:, selected_features], y, test_size=0.3, random_state=42\n",
        "        # , stratify=y                                # aktifkan ini agar proporsi kelas seimbang\n",
        "    )\n",
        "\n",
        "    # Buat & latih model Decision Tree\n",
        "    clf = DecisionTree(max_depth=5)                   # pohon dengan kedalaman maks 5\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Prediksi dan evaluasi\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(\"\\n=== HASIL EVALUASI ===\")\n",
        "    print(\"Akurasi:\", accuracy_score(y_test, y_pred)) # metrik akurasi\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))           # confusion matrix\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))      # precision/recall/f1 per kelas\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
